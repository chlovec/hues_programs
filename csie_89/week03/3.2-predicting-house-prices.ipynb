{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCIE89 - Keras Intro #\n",
    "\n",
    "Credits : This notebook contains code adapted from the book Deep Learning with Python by Francois Chollet\n",
    "Chapter 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices: a regression example\n",
    "\n",
    "This notebook contains the code samples found in Chapter 3, Section 6 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). \n",
    "\n",
    "---\n",
    "A common type of machine learning problem is \"regression\", which consists of predicting a continuous value instead \n",
    "of a discrete label. For instance, predicting the temperature tomorrow, given meteorological data, or predicting the time that a \n",
    "software project will take to complete, given its specifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.0'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Boston Housing Price dataset\n",
    "\n",
    "\n",
    "We will be attempting to predict the median price of homes in a given Boston suburb in the mid-1970s, given a few data points about the \n",
    "suburb at the time, such as the crime rate, the local property tax rate, etc.\n",
    "\n",
    "The dataset we will be using has another interesting difference from our two previous examples: it has very few data points, only 506 in \n",
    "total, split between 404 training samples and 102 test samples, and each \"feature\" in the input data (e.g. the crime rate is a feature) has \n",
    "a different scale. For instance some values are proportions, which take a values between 0 and 1, others take values between 1 and 12, \n",
    "others between 0 and 100...\n",
    "\n",
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can see, we have 404 training samples and 102 test samples. The data comprises 13 features. The 13 features in the input data are as \n",
    "follow:\n",
    "\n",
    "1. Per capita crime rate.\n",
    "2. Proportion of residential land zoned for lots over 25,000 square feet.\n",
    "3. Proportion of non-retail business acres per town.\n",
    "4. Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "5. Nitric oxides concentration (parts per 10 million).\n",
    "6. Average number of rooms per dwelling.\n",
    "7. Proportion of owner-occupied units built prior to 1940.\n",
    "8. Weighted distances to five Boston employment centres.\n",
    "9. Index of accessibility to radial highways.\n",
    "10. Full-value property-tax rate per $10,000.\n",
    "11. Pupil-teacher ratio by town.\n",
    "12. 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
    "13. % lower status of the population.\n",
    "\n",
    "The targets are the median values of owner-occupied homes, in thousands of dollars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The prices are typically between \\$10,000  and  \\$50,000. If that sounds cheap, remember this was the mid-1970s, and these prices are not \n",
    "inflation-adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data, Normalization\n",
    "\n",
    "\n",
    "It would be problematic to feed into a neural network values that all take wildly different ranges. The network might be able to \n",
    "automatically adapt to such heterogeneous data, but it would definitely make learning more difficult. A widespread best practice to deal \n",
    "with such data is to do feature-wise normalization: for each feature in the input data (a column in the input data matrix), we \n",
    "will subtract the mean of the feature and divide by the standard deviation, so that the feature will be centered around 0 and will have a \n",
    "unit standard deviation. This is easily done in Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  [-1.01541438e-16  1.09923072e-17  1.80933376e-15 -7.80453809e-17\n",
      " -5.25047552e-15  6.43187374e-15  2.98441140e-16  4.94653823e-16\n",
      "  1.12671149e-17 -1.05526149e-16  2.36614908e-14  5.96710525e-15\n",
      "  6.13920356e-16]\n",
      "std:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"mean: \", mean)\n",
    "print(\"std: \", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network\n",
    "\n",
    "\n",
    "Because so few samples are available, we will be using a very small network with two \n",
    "hidden layers, each with 64 units. In general, the less training data you have, the worse overfitting will be, and using \n",
    "a small network is one way to mitigate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our network ends with a single unit, and no activation (i.e. it will be linear layer). \n",
    "This is a typical setup for scalar regression (i.e. regression where we are trying to predict a single continuous value). \n",
    "\n",
    "Note that we are compiling the network with the `mse` loss function -- Mean Squared Error, the square of the difference between the \n",
    "predictions and the targets, a widely used loss function for regression problems.\n",
    "\n",
    "We are also monitoring a new metric during training: `mae`. This stands for Mean Absolute Error. It is simply the absolute value of the \n",
    "difference between the predictions and the targets. For instance, a MAE of 0.5 on this problem would mean that our predictions are off by \n",
    "\\$500 on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating our approach using K-fold validation\n",
    "\n",
    "\n",
    "To evaluate our network while we keep adjusting its parameters (such as the number of epochs used for training), we could simply split the \n",
    "data into a training set and a validation set, as we were doing in our previous examples. However, because we have so few data points, the \n",
    "validation set would end up being very small (e.g. about 100 examples). A consequence is that our validation scores may change a lot \n",
    "depending on _which_ data points we choose to use for validation and which we choose for training, i.e. the validation scores may have a \n",
    "high _variance_ with regard to the validation split. This would prevent us from reliably evaluating our model.\n",
    "\n",
    "The best practice in such situations is to use K-fold cross-validation. It consists of splitting the available data into K partitions \n",
    "(typically K=4 or 5), then instantiating K identical models, and training each one on K-1 partitions while evaluating on the remaining \n",
    "partition. The validation score for the model used would then be the average of the K validation scores obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of code, this is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 394.4415 - mae: 17.7354\n",
      "Epoch 2/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - loss: 44.3452 - mae: 4.7249\n",
      "Epoch 3/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 21.7425 - mae: 3.2920\n",
      "Epoch 4/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - loss: 20.3377 - mae: 2.9553\n",
      "Epoch 5/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 21.2087 - mae: 2.9193\n",
      "Epoch 6/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 29.4988 - mae: 3.2519\n",
      "Epoch 7/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 31.7103 - mae: 3.2496\n",
      "Epoch 8/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 10.4465 - mae: 2.3341\n",
      "Epoch 9/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 24.3236 - mae: 2.9771\n",
      "Epoch 10/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - loss: 10.6770 - mae: 2.2378\n",
      "Epoch 11/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - loss: 8.8102 - mae: 2.0725\n",
      "Epoch 12/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 11.4404 - mae: 2.3825\n",
      "Epoch 13/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - loss: 9.2269 - mae: 2.0430\n",
      "Epoch 14/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 9.7590 - mae: 2.0381\n",
      "Epoch 15/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - loss: 10.7918 - mae: 2.2917\n",
      "Epoch 16/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - loss: 11.3189 - mae: 2.1250\n",
      "Epoch 17/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - loss: 6.2230 - mae: 1.7893\n",
      "Epoch 18/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - loss: 13.8548 - mae: 2.2135\n",
      "Epoch 19/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 5.6551 - mae: 1.6457\n",
      "Epoch 20/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 7.6581 - mae: 1.9316\n",
      "Epoch 21/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - loss: 11.7098 - mae: 2.0505\n",
      "Epoch 22/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 9.0821 - mae: 2.0452\n",
      "Epoch 23/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 9.0234 - mae: 1.9588\n",
      "Epoch 24/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 23.1735 - mae: 2.5789\n",
      "Epoch 25/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 8.0522 - mae: 1.9256\n",
      "Epoch 26/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 8.5756 - mae: 1.9628\n",
      "Epoch 27/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 7.3658 - mae: 1.8601\n",
      "Epoch 28/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 14.1146 - mae: 2.0058 \n",
      "Epoch 29/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - loss: 7.2884 - mae: 1.9479\n",
      "Epoch 30/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 5.3146 - mae: 1.5645\n",
      "Epoch 31/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - loss: 10.3837 - mae: 2.0740\n",
      "Epoch 32/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 13.2218 - mae: 2.1683\n",
      "Epoch 33/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 10.6969 - mae: 1.9791\n",
      "Epoch 34/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - loss: 7.0814 - mae: 1.8406\n",
      "Epoch 35/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 10.0130 - mae: 1.8893\n",
      "Epoch 36/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - loss: 10.4863 - mae: 1.8111\n",
      "Epoch 37/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 5.7164 - mae: 1.6880\n",
      "Epoch 38/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 11.5324 - mae: 2.0489\n",
      "Epoch 39/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - loss: 4.7408 - mae: 1.5872\n",
      "Epoch 40/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 8.2572 - mae: 1.6772\n",
      "Epoch 41/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 12.7802 - mae: 2.0751\n",
      "Epoch 42/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 7.3803 - mae: 1.7491\n",
      "Epoch 43/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - loss: 6.4770 - mae: 1.6614\n",
      "Epoch 44/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - loss: 6.7647 - mae: 1.7179\n",
      "Epoch 45/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 6.0433 - mae: 1.5837\n",
      "Epoch 46/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 6.0173 - mae: 1.4905\n",
      "Epoch 47/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - loss: 8.7899 - mae: 1.7763\n",
      "Epoch 48/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - loss: 5.5877 - mae: 1.5391\n",
      "Epoch 49/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - loss: 10.5283 - mae: 2.0413\n",
      "Epoch 50/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - loss: 8.1637 - mae: 1.6377\n",
      "Epoch 51/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - loss: 5.2703 - mae: 1.5357\n",
      "Epoch 52/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - loss: 3.5538 - mae: 1.3411\n",
      "Epoch 53/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - loss: 6.5615 - mae: 1.6618\n",
      "Epoch 54/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 6.1316 - mae: 1.5253\n",
      "Epoch 55/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - loss: 6.8323 - mae: 1.5277\n",
      "Epoch 56/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - loss: 4.2928 - mae: 1.2286\n",
      "Epoch 57/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - loss: 6.0163 - mae: 1.4790\n",
      "Epoch 58/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - loss: 4.8736 - mae: 1.4697\n",
      "Epoch 59/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - loss: 7.8798 - mae: 1.5872\n",
      "Epoch 60/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 4.3587 - mae: 1.2208\n",
      "Epoch 61/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 4.4980 - mae: 1.2655\n",
      "Epoch 62/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - loss: 7.4280 - mae: 1.7590\n",
      "Epoch 63/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - loss: 4.8611 - mae: 1.2382\n",
      "Epoch 64/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 3.6197 - mae: 1.2797\n",
      "Epoch 65/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 5.6596 - mae: 1.4270\n",
      "Epoch 66/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - loss: 4.3273 - mae: 1.4169\n",
      "Epoch 67/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - loss: 4.5153 - mae: 1.4057\n",
      "Epoch 68/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - loss: 8.3028 - mae: 1.5558\n",
      "Epoch 69/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - loss: 4.3617 - mae: 1.3961\n",
      "Epoch 70/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - loss: 6.9484 - mae: 1.5894\n",
      "Epoch 71/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 13.9970 - mae: 1.6990\n",
      "Epoch 72/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - loss: 6.3596 - mae: 1.3771\n",
      "Epoch 73/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 5.3768 - mae: 1.3755\n",
      "Epoch 74/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - loss: 4.3783 - mae: 1.3515\n",
      "Epoch 75/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - loss: 5.3082 - mae: 1.3702\n",
      "Epoch 76/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - loss: 4.7671 - mae: 1.3944\n",
      "Epoch 77/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - loss: 3.8030 - mae: 1.2074\n",
      "Epoch 78/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - loss: 4.2769 - mae: 1.3366\n",
      "Epoch 79/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 8.6846 - mae: 1.4834\n",
      "Epoch 80/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 3.3492 - mae: 1.2043\n",
      "Epoch 81/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 3.9860 - mae: 1.3508\n",
      "Epoch 82/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - loss: 4.7837 - mae: 1.3619\n",
      "Epoch 83/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - loss: 4.9253 - mae: 1.3209\n",
      "Epoch 84/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - loss: 4.7714 - mae: 1.4022\n",
      "Epoch 85/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 4.3639 - mae: 1.2397\n",
      "Epoch 86/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - loss: 3.9935 - mae: 1.2825\n",
      "Epoch 87/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - loss: 4.3402 - mae: 1.3472\n",
      "Epoch 88/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - loss: 4.3418 - mae: 1.2540\n",
      "Epoch 89/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 3.3385 - mae: 1.2330\n",
      "Epoch 90/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 6.2200 - mae: 1.4368\n",
      "Epoch 91/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - loss: 4.7786 - mae: 1.3448\n",
      "Epoch 92/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - loss: 2.7083 - mae: 1.1161\n",
      "Epoch 93/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - loss: 5.4620 - mae: 1.2352\n",
      "Epoch 94/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - loss: 2.6357 - mae: 1.0965\n",
      "Epoch 95/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 4.6136 - mae: 1.3343\n",
      "Epoch 96/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - loss: 6.2234 - mae: 1.2384\n",
      "Epoch 97/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 4.5711 - mae: 1.2829\n",
      "Epoch 98/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - loss: 5.5381 - mae: 1.3494\n",
      "Epoch 99/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 6.0233 - mae: 1.4142\n",
      "Epoch 100/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - loss: 8.1497 - mae: 1.3250\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - loss: 469.3892 - mae: 18.7688\n",
      "Epoch 2/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 52.9991 - mae: 4.8877\n",
      "Epoch 3/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 27.4113 - mae: 3.5847\n",
      "Epoch 4/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 28.0635 - mae: 3.2864\n",
      "Epoch 5/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 18.5784 - mae: 2.7672\n",
      "Epoch 6/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 16.1178 - mae: 2.7826\n",
      "Epoch 7/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - loss: 13.1029 - mae: 2.4589\n",
      "Epoch 8/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 17.0792 - mae: 2.5325\n",
      "Epoch 9/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - loss: 14.4879 - mae: 2.4785\n",
      "Epoch 10/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - loss: 7.8065 - mae: 1.9370\n",
      "Epoch 11/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 8.4161 - mae: 2.0844\n",
      "Epoch 12/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - loss: 13.1768 - mae: 2.3322\n",
      "Epoch 13/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - loss: 11.0630 - mae: 2.1135\n",
      "Epoch 14/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - loss: 7.0709 - mae: 1.8368\n",
      "Epoch 15/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - loss: 8.9058 - mae: 2.0042\n",
      "Epoch 16/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 6.2437 - mae: 1.8836\n",
      "Epoch 17/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step - loss: 6.3738 - mae: 1.7128\n",
      "Epoch 18/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 9.2954 - mae: 2.0530\n",
      "Epoch 19/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - loss: 6.3147 - mae: 1.7659\n",
      "Epoch 20/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 8.3347 - mae: 1.8759\n",
      "Epoch 21/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 5.1252 - mae: 1.5764\n",
      "Epoch 22/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 6.3903 - mae: 1.7578\n",
      "Epoch 23/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - loss: 4.8063 - mae: 1.5694\n",
      "Epoch 24/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - loss: 6.2199 - mae: 1.8049\n",
      "Epoch 25/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 4.2537 - mae: 1.5989\n",
      "Epoch 26/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 5.1559 - mae: 1.6249\n",
      "Epoch 27/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - loss: 4.6493 - mae: 1.5173\n",
      "Epoch 28/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - loss: 5.8536 - mae: 1.6950\n",
      "Epoch 29/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 5.6537 - mae: 1.7349\n",
      "Epoch 30/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - loss: 5.1362 - mae: 1.6762\n",
      "Epoch 31/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - loss: 5.3629 - mae: 1.6528\n",
      "Epoch 32/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - loss: 5.2320 - mae: 1.6524\n",
      "Epoch 33/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - loss: 3.1898 - mae: 1.2405\n",
      "Epoch 34/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - loss: 4.3911 - mae: 1.5237\n",
      "Epoch 35/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - loss: 4.3350 - mae: 1.4540\n",
      "Epoch 36/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 3.1539 - mae: 1.3559\n",
      "Epoch 37/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 3.6067 - mae: 1.3364\n",
      "Epoch 38/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 4.2346 - mae: 1.4692\n",
      "Epoch 39/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 4.2100 - mae: 1.4542\n",
      "Epoch 40/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 3.1795 - mae: 1.3308\n",
      "Epoch 41/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - loss: 3.7223 - mae: 1.4351\n",
      "Epoch 42/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 4.1955 - mae: 1.5404\n",
      "Epoch 43/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - loss: 3.5083 - mae: 1.3811\n",
      "Epoch 44/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 3.5256 - mae: 1.4701\n",
      "Epoch 45/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 3.7892 - mae: 1.4912\n",
      "Epoch 46/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - loss: 3.5559 - mae: 1.4553\n",
      "Epoch 47/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - loss: 2.5830 - mae: 1.1584\n",
      "Epoch 48/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 3.3902 - mae: 1.3766\n",
      "Epoch 49/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 3.4070 - mae: 1.4348\n",
      "Epoch 50/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - loss: 3.0018 - mae: 1.2778\n",
      "Epoch 51/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - loss: 3.3170 - mae: 1.3754\n",
      "Epoch 52/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - loss: 3.3752 - mae: 1.3401\n",
      "Epoch 53/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step - loss: 3.3522 - mae: 1.3063\n",
      "Epoch 54/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 3.1103 - mae: 1.4336\n",
      "Epoch 55/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 2.9953 - mae: 1.3345\n",
      "Epoch 56/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - loss: 3.0033 - mae: 1.3120\n",
      "Epoch 57/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 2.2254 - mae: 1.1068\n",
      "Epoch 58/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - loss: 2.6691 - mae: 1.2650\n",
      "Epoch 59/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 2.9399 - mae: 1.2816\n",
      "Epoch 60/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274us/step - loss: 2.2101 - mae: 1.1241\n",
      "Epoch 61/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - loss: 2.6386 - mae: 1.2388\n",
      "Epoch 62/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 3.3183 - mae: 1.4104\n",
      "Epoch 63/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 2.7581 - mae: 1.2844\n",
      "Epoch 64/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 3.3946 - mae: 1.3685\n",
      "Epoch 65/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 2.2918 - mae: 1.1779\n",
      "Epoch 66/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - loss: 2.4840 - mae: 1.2739\n",
      "Epoch 67/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - loss: 2.6875 - mae: 1.1893\n",
      "Epoch 68/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 2.2997 - mae: 1.1962\n",
      "Epoch 69/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - loss: 2.3576 - mae: 1.1713\n",
      "Epoch 70/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - loss: 2.5106 - mae: 1.2115\n",
      "Epoch 71/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - loss: 2.8742 - mae: 1.1659\n",
      "Epoch 72/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - loss: 1.9953 - mae: 1.0812\n",
      "Epoch 73/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - loss: 2.3748 - mae: 1.1329\n",
      "Epoch 74/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 2.0109 - mae: 1.1136\n",
      "Epoch 75/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 2.3762 - mae: 1.1997\n",
      "Epoch 76/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 2.3240 - mae: 1.1901\n",
      "Epoch 77/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 2.0222 - mae: 1.0349\n",
      "Epoch 78/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - loss: 2.7992 - mae: 1.2338\n",
      "Epoch 79/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 2.0192 - mae: 1.0671\n",
      "Epoch 80/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 2.1781 - mae: 1.1265\n",
      "Epoch 81/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 2.2411 - mae: 1.1211\n",
      "Epoch 82/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - loss: 2.2705 - mae: 1.1295\n",
      "Epoch 83/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 2.2696 - mae: 1.0944\n",
      "Epoch 84/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - loss: 1.8809 - mae: 1.0413\n",
      "Epoch 85/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - loss: 2.2642 - mae: 1.1008\n",
      "Epoch 86/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - loss: 2.1536 - mae: 1.0813\n",
      "Epoch 87/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - loss: 1.9425 - mae: 1.0364\n",
      "Epoch 88/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 2.5281 - mae: 1.2005\n",
      "Epoch 89/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 1.8905 - mae: 1.0732\n",
      "Epoch 90/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - loss: 1.8572 - mae: 0.9968\n",
      "Epoch 91/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - loss: 1.5264 - mae: 1.0004\n",
      "Epoch 92/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 1.8402 - mae: 1.0522\n",
      "Epoch 93/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - loss: 2.0945 - mae: 1.0668\n",
      "Epoch 94/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 2.4475 - mae: 1.1256\n",
      "Epoch 95/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - loss: 1.4308 - mae: 0.9011\n",
      "Epoch 96/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 1.5248 - mae: 0.9416\n",
      "Epoch 97/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - loss: 1.6036 - mae: 0.9321\n",
      "Epoch 98/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 1.5694 - mae: 0.9394\n",
      "Epoch 99/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 1.4663 - mae: 0.8688\n",
      "Epoch 100/100\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - loss: 1.5412 - mae: 0.9496\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 2\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    # Evaluate the model on the validation data\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.502548933029175, 2.7961878776550293]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.649368405342102"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can notice, the different runs do indeed show rather different validation scores, from 2.17 to 2.90. Their average (2.45) is a much more \n",
    "reliable metric than any single of these scores -- that's the entire point of K-fold cross-validation. In this case, we are off by  2,500   on \n",
    "average, which is still significant considering that the prices range from  10,000  to  50,000. \n",
    "1\n",
    "Let's try training the network for a bit longer: 200 epochs. \n",
    "To keep a record of how well the model did at each epoch, we will modify our training loop to save the per-epoch validation score log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Some memory clean-up\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 429.9024 - mae: 18.2662 - val_loss: 40.8251 - val_mae: 4.5297\n",
      "Epoch 2/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 37.1502 - mae: 4.4611 - val_loss: 30.9979 - val_mae: 4.2012\n",
      "Epoch 3/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 27.9270 - mae: 3.8513 - val_loss: 20.3540 - val_mae: 3.0724\n",
      "Epoch 4/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 44.1342 - mae: 3.7276 - val_loss: 18.2507 - val_mae: 2.9726\n",
      "Epoch 5/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 15.1135 - mae: 2.6356 - val_loss: 18.2044 - val_mae: 3.1927\n",
      "Epoch 6/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 21.2939 - mae: 2.8157 - val_loss: 14.8126 - val_mae: 2.6895\n",
      "Epoch 7/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 20.4714 - mae: 2.5512 - val_loss: 15.1085 - val_mae: 2.7699\n",
      "Epoch 8/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 17.0185 - mae: 2.7441 - val_loss: 14.2848 - val_mae: 2.7865\n",
      "Epoch 9/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 12.1436 - mae: 2.3626 - val_loss: 14.3296 - val_mae: 2.6295\n",
      "Epoch 10/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 15.2981 - mae: 2.4622 - val_loss: 11.8451 - val_mae: 2.5098\n",
      "Epoch 11/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 11.7361 - mae: 2.2593 - val_loss: 12.2300 - val_mae: 2.5485\n",
      "Epoch 12/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 17.6770 - mae: 2.6373 - val_loss: 11.4524 - val_mae: 2.4743\n",
      "Epoch 13/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 20.5316 - mae: 2.5662 - val_loss: 11.1755 - val_mae: 2.4417\n",
      "Epoch 14/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 10.8529 - mae: 2.2347 - val_loss: 10.9391 - val_mae: 2.2903\n",
      "Epoch 15/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 10.0446 - mae: 2.1609 - val_loss: 10.9868 - val_mae: 2.2999\n",
      "Epoch 16/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 8.8257 - mae: 1.9980 - val_loss: 10.9804 - val_mae: 2.3538\n",
      "Epoch 17/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 9.2058 - mae: 1.9243 - val_loss: 10.7121 - val_mae: 2.4666\n",
      "Epoch 18/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 7.4748 - mae: 1.8723 - val_loss: 11.1906 - val_mae: 2.5292\n",
      "Epoch 19/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 9.9703 - mae: 2.0960 - val_loss: 11.1190 - val_mae: 2.5108\n",
      "Epoch 20/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 9.8520 - mae: 1.9976 - val_loss: 11.2130 - val_mae: 2.5506\n",
      "Epoch 21/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 7.3296 - mae: 1.7949 - val_loss: 12.8093 - val_mae: 2.8009\n",
      "Epoch 22/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 17.7689 - mae: 2.2961 - val_loss: 13.0824 - val_mae: 2.8974\n",
      "Epoch 23/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 11.1249 - mae: 2.2187 - val_loss: 10.5719 - val_mae: 2.4756\n",
      "Epoch 24/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 8.4903 - mae: 1.9780 - val_loss: 11.1541 - val_mae: 2.5948\n",
      "Epoch 25/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 8.8641 - mae: 2.0302 - val_loss: 9.3570 - val_mae: 2.2114\n",
      "Epoch 26/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 7.3200 - mae: 1.8817 - val_loss: 11.6296 - val_mae: 2.6363\n",
      "Epoch 27/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 9.2632 - mae: 2.0257 - val_loss: 10.5264 - val_mae: 2.4939\n",
      "Epoch 28/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 12.0142 - mae: 1.9686 - val_loss: 13.3313 - val_mae: 2.8960\n",
      "Epoch 29/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 7.0315 - mae: 1.9173 - val_loss: 13.2396 - val_mae: 2.8058\n",
      "Epoch 30/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 18.5082 - mae: 2.4994 - val_loss: 11.2441 - val_mae: 2.6406\n",
      "Epoch 31/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 11.0772 - mae: 2.0339 - val_loss: 11.0649 - val_mae: 2.4163\n",
      "Epoch 32/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 11.3956 - mae: 1.9832 - val_loss: 9.0331 - val_mae: 2.1841\n",
      "Epoch 33/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 10.2862 - mae: 1.9530 - val_loss: 10.7185 - val_mae: 2.5523\n",
      "Epoch 34/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 10.4216 - mae: 1.8713 - val_loss: 11.3537 - val_mae: 2.6332\n",
      "Epoch 35/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 9.3820 - mae: 2.0139 - val_loss: 10.3865 - val_mae: 2.4800\n",
      "Epoch 36/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 8.9764 - mae: 1.8900 - val_loss: 10.0578 - val_mae: 2.3733\n",
      "Epoch 37/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 14.2732 - mae: 2.1079 - val_loss: 9.2498 - val_mae: 2.2685\n",
      "Epoch 38/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 8.0218 - mae: 1.9116 - val_loss: 9.6556 - val_mae: 2.2765\n",
      "Epoch 39/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 13.3408 - mae: 1.9914 - val_loss: 9.2254 - val_mae: 2.2279\n",
      "Epoch 40/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 8.3548 - mae: 1.7366 - val_loss: 9.0245 - val_mae: 2.2273\n",
      "Epoch 41/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 6.5118 - mae: 1.7177 - val_loss: 10.3897 - val_mae: 2.4765\n",
      "Epoch 42/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 8.1433 - mae: 1.8708 - val_loss: 11.3672 - val_mae: 2.6111\n",
      "Epoch 43/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 8.9926 - mae: 1.8789 - val_loss: 9.3336 - val_mae: 2.2976\n",
      "Epoch 44/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 9.3806 - mae: 1.8538 - val_loss: 9.7965 - val_mae: 2.3356\n",
      "Epoch 45/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 19.0710 - mae: 2.1281 - val_loss: 9.3926 - val_mae: 2.3114\n",
      "Epoch 46/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 4.9094 - mae: 1.5434 - val_loss: 10.2125 - val_mae: 2.4199\n",
      "Epoch 47/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 7.3211 - mae: 1.8887 - val_loss: 11.4513 - val_mae: 2.7079\n",
      "Epoch 48/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 5.5947 - mae: 1.5585 - val_loss: 8.8539 - val_mae: 2.1805\n",
      "Epoch 49/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 17.1386 - mae: 2.0985 - val_loss: 9.3207 - val_mae: 2.2413\n",
      "Epoch 50/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 7.1067 - mae: 1.7232 - val_loss: 9.6072 - val_mae: 2.2359\n",
      "Epoch 51/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 5.5236 - mae: 1.6287 - val_loss: 10.7962 - val_mae: 2.3970\n",
      "Epoch 52/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 4.8696 - mae: 1.5418 - val_loss: 9.3440 - val_mae: 2.2583\n",
      "Epoch 53/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 8.3136 - mae: 1.7457 - val_loss: 9.8625 - val_mae: 2.3491\n",
      "Epoch 54/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 4.4071 - mae: 1.5048 - val_loss: 10.5630 - val_mae: 2.5099\n",
      "Epoch 55/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 4.6930 - mae: 1.5573 - val_loss: 10.1697 - val_mae: 2.4770\n",
      "Epoch 56/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 10.4494 - mae: 1.9067 - val_loss: 8.5544 - val_mae: 2.1219\n",
      "Epoch 57/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 5.2282 - mae: 1.6174 - val_loss: 9.9061 - val_mae: 2.3525\n",
      "Epoch 58/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 4.1108 - mae: 1.4689 - val_loss: 10.4057 - val_mae: 2.4511\n",
      "Epoch 59/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 8.9852 - mae: 1.8547 - val_loss: 8.9496 - val_mae: 2.1624\n",
      "Epoch 60/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 7.4238 - mae: 1.4396 - val_loss: 10.4006 - val_mae: 2.4861\n",
      "Epoch 61/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 3.9415 - mae: 1.4543 - val_loss: 12.5366 - val_mae: 2.7465\n",
      "Epoch 62/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 8.1091 - mae: 1.8147 - val_loss: 10.3524 - val_mae: 2.4602\n",
      "Epoch 63/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 5.4957 - mae: 1.5854 - val_loss: 9.8671 - val_mae: 2.4064\n",
      "Epoch 64/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 4.8180 - mae: 1.3552 - val_loss: 11.1906 - val_mae: 2.5970\n",
      "Epoch 65/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 6.0111 - mae: 1.5019 - val_loss: 9.2373 - val_mae: 2.2162\n",
      "Epoch 66/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 6.4463 - mae: 1.6442 - val_loss: 9.5577 - val_mae: 2.3647\n",
      "Epoch 67/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 11.5250 - mae: 1.9729 - val_loss: 9.1798 - val_mae: 2.1834\n",
      "Epoch 68/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 6.2657 - mae: 1.4364 - val_loss: 10.0619 - val_mae: 2.4102\n",
      "Epoch 69/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 12.9570 - mae: 1.8797 - val_loss: 10.4404 - val_mae: 2.4931\n",
      "Epoch 70/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 9.5532 - mae: 1.6429 - val_loss: 10.1175 - val_mae: 2.3536\n",
      "Epoch 71/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 6.4140 - mae: 1.6665 - val_loss: 8.7468 - val_mae: 2.1921\n",
      "Epoch 72/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 3.8410 - mae: 1.4321 - val_loss: 10.7782 - val_mae: 2.5382\n",
      "Epoch 73/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 6.4258 - mae: 1.5520 - val_loss: 9.4869 - val_mae: 2.3402\n",
      "Epoch 74/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 5.9349 - mae: 1.5305 - val_loss: 9.5687 - val_mae: 2.3500\n",
      "Epoch 75/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 3.7704 - mae: 1.3614 - val_loss: 11.1755 - val_mae: 2.5689\n",
      "Epoch 76/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 6.6640 - mae: 1.4556 - val_loss: 9.9535 - val_mae: 2.3546\n",
      "Epoch 77/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 3.2894 - mae: 1.3161 - val_loss: 11.6114 - val_mae: 2.6097\n",
      "Epoch 78/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 5.2247 - mae: 1.4698 - val_loss: 10.5422 - val_mae: 2.4518\n",
      "Epoch 79/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 5.6899 - mae: 1.4561 - val_loss: 11.5248 - val_mae: 2.5776\n",
      "Epoch 80/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 3.9976 - mae: 1.3339 - val_loss: 9.7979 - val_mae: 2.2988\n",
      "Epoch 81/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 6.5464 - mae: 1.4694 - val_loss: 12.2198 - val_mae: 2.6454\n",
      "Epoch 82/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 3.9670 - mae: 1.3682 - val_loss: 9.3730 - val_mae: 2.2528\n",
      "Epoch 83/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 3.0105 - mae: 1.2837 - val_loss: 11.4094 - val_mae: 2.5502\n",
      "Epoch 84/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 4.2222 - mae: 1.3829 - val_loss: 9.3146 - val_mae: 2.2337\n",
      "Epoch 85/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 6.4429 - mae: 1.3269 - val_loss: 10.4429 - val_mae: 2.4194\n",
      "Epoch 86/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 6.6948 - mae: 1.5339 - val_loss: 9.1296 - val_mae: 2.2213\n",
      "Epoch 87/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 3.6996 - mae: 1.3653 - val_loss: 11.9129 - val_mae: 2.6917\n",
      "Epoch 88/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 7.5773 - mae: 1.5154 - val_loss: 11.5356 - val_mae: 2.6346\n",
      "Epoch 89/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 4.6262 - mae: 1.4064 - val_loss: 9.8462 - val_mae: 2.3763\n",
      "Epoch 90/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 5.4978 - mae: 1.4539 - val_loss: 10.9988 - val_mae: 2.5245\n",
      "Epoch 91/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 4.6720 - mae: 1.3796 - val_loss: 9.5360 - val_mae: 2.3568\n",
      "Epoch 92/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 2.3521 - mae: 1.1207 - val_loss: 10.3179 - val_mae: 2.3885\n",
      "Epoch 93/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 4.3392 - mae: 1.4552 - val_loss: 10.2631 - val_mae: 2.4151\n",
      "Epoch 94/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 4.7434 - mae: 1.4096 - val_loss: 10.3079 - val_mae: 2.3928\n",
      "Epoch 95/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 3.5634 - mae: 1.2311 - val_loss: 10.0707 - val_mae: 2.3865\n",
      "Epoch 96/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 2.8465 - mae: 1.1505 - val_loss: 10.8379 - val_mae: 2.4733\n",
      "Epoch 97/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 5.4236 - mae: 1.5235 - val_loss: 9.9707 - val_mae: 2.4519\n",
      "Epoch 98/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 2.9189 - mae: 1.2242 - val_loss: 9.3480 - val_mae: 2.2728\n",
      "Epoch 99/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 3.2489 - mae: 1.2530 - val_loss: 10.6702 - val_mae: 2.5179\n",
      "Epoch 100/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 3.0352 - mae: 1.2659 - val_loss: 10.1240 - val_mae: 2.4529\n",
      "Epoch 101/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 2.8837 - mae: 1.2323 - val_loss: 9.2737 - val_mae: 2.2487\n",
      "Epoch 102/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 4.0130 - mae: 1.3561 - val_loss: 9.9459 - val_mae: 2.3556\n",
      "Epoch 103/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 8.6102 - mae: 1.5472 - val_loss: 10.4800 - val_mae: 2.3842\n",
      "Epoch 104/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 2.5252 - mae: 1.1326 - val_loss: 12.8989 - val_mae: 2.7211\n",
      "Epoch 105/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 3.3003 - mae: 1.2116 - val_loss: 10.9509 - val_mae: 2.4463\n",
      "Epoch 106/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 6.9843 - mae: 1.4806 - val_loss: 10.8067 - val_mae: 2.5134\n",
      "Epoch 107/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 3.0308 - mae: 1.1147 - val_loss: 9.4965 - val_mae: 2.3184\n",
      "Epoch 108/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 4.7369 - mae: 1.3362 - val_loss: 9.2947 - val_mae: 2.2629\n",
      "Epoch 109/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 4.0112 - mae: 1.2744 - val_loss: 11.2444 - val_mae: 2.5276\n",
      "Epoch 110/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 4.0011 - mae: 1.3795 - val_loss: 10.7974 - val_mae: 2.5107\n",
      "Epoch 111/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 3.8994 - mae: 1.3439 - val_loss: 9.8156 - val_mae: 2.3719\n",
      "Epoch 112/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 2.9358 - mae: 1.1078 - val_loss: 11.5112 - val_mae: 2.5216\n",
      "Epoch 113/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 3.5158 - mae: 1.2217 - val_loss: 14.2999 - val_mae: 2.9832\n",
      "Epoch 114/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 3.8375 - mae: 1.3490 - val_loss: 10.1880 - val_mae: 2.4133\n",
      "Epoch 115/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 3.5755 - mae: 1.1464 - val_loss: 12.7567 - val_mae: 2.8281\n",
      "Epoch 116/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 5.3635 - mae: 1.4113 - val_loss: 9.6742 - val_mae: 2.3216\n",
      "Epoch 117/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 3.4530 - mae: 1.2200 - val_loss: 10.3757 - val_mae: 2.3824\n",
      "Epoch 118/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 4.8750 - mae: 1.2867 - val_loss: 12.5663 - val_mae: 2.6500\n",
      "Epoch 119/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 2.3990 - mae: 1.1163 - val_loss: 10.8028 - val_mae: 2.5244\n",
      "Epoch 120/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 4.1134 - mae: 1.1466 - val_loss: 11.4333 - val_mae: 2.5128\n",
      "Epoch 121/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 5.4987 - mae: 1.4146 - val_loss: 11.5124 - val_mae: 2.4633\n",
      "Epoch 122/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 3.4563 - mae: 1.2127 - val_loss: 12.4574 - val_mae: 2.7400\n",
      "Epoch 123/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 3.4014 - mae: 1.1384 - val_loss: 11.0209 - val_mae: 2.4240\n",
      "Epoch 124/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 2.5440 - mae: 1.1070 - val_loss: 13.9545 - val_mae: 2.8099\n",
      "Epoch 125/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 3.6932 - mae: 1.2202 - val_loss: 10.3175 - val_mae: 2.3919\n",
      "Epoch 126/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 4.3847 - mae: 1.2385 - val_loss: 10.6916 - val_mae: 2.4134\n",
      "Epoch 127/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 3.5519 - mae: 1.1307 - val_loss: 11.4475 - val_mae: 2.4791\n",
      "Epoch 128/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 2.8249 - mae: 1.1918 - val_loss: 11.0263 - val_mae: 2.3296\n",
      "Epoch 129/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 4.8288 - mae: 1.2225 - val_loss: 10.2198 - val_mae: 2.3488\n",
      "Epoch 130/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 2.0402 - mae: 1.0583 - val_loss: 14.0984 - val_mae: 2.7354\n",
      "Epoch 131/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 1.9898 - mae: 1.0136 - val_loss: 19.1937 - val_mae: 3.2177\n",
      "Epoch 132/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 4.8691 - mae: 1.4042 - val_loss: 11.1449 - val_mae: 2.5651\n",
      "Epoch 133/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 2.7304 - mae: 1.1368 - val_loss: 11.8176 - val_mae: 2.5710\n",
      "Epoch 134/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 2.5254 - mae: 1.0921 - val_loss: 12.0799 - val_mae: 2.6056\n",
      "Epoch 135/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 2.4857 - mae: 1.0665 - val_loss: 9.2914 - val_mae: 2.2934\n",
      "Epoch 136/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 2.7297 - mae: 1.0461 - val_loss: 11.9406 - val_mae: 2.5840\n",
      "Epoch 137/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 2.2571 - mae: 1.0890 - val_loss: 12.7033 - val_mae: 2.6055\n",
      "Epoch 138/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 4.0134 - mae: 1.2628 - val_loss: 10.6408 - val_mae: 2.4354\n",
      "Epoch 139/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 2.1983 - mae: 1.0437 - val_loss: 11.6675 - val_mae: 2.5750\n",
      "Epoch 140/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 3.4874 - mae: 1.1224 - val_loss: 12.7151 - val_mae: 2.6533\n",
      "Epoch 141/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 3.4989 - mae: 1.1893 - val_loss: 11.6483 - val_mae: 2.6262\n",
      "Epoch 142/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 2.3295 - mae: 1.0857 - val_loss: 10.1452 - val_mae: 2.3477\n",
      "Epoch 143/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 3.6893 - mae: 1.2589 - val_loss: 10.9647 - val_mae: 2.4865\n",
      "Epoch 144/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 2.1222 - mae: 0.9733 - val_loss: 11.1458 - val_mae: 2.4893\n",
      "Epoch 145/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 2.0988 - mae: 1.0064 - val_loss: 10.5108 - val_mae: 2.4362\n",
      "Epoch 146/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 3.0130 - mae: 1.1267 - val_loss: 12.9548 - val_mae: 2.8031\n",
      "Epoch 147/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 2.6775 - mae: 1.0910 - val_loss: 9.3285 - val_mae: 2.2869\n",
      "Epoch 148/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 1.9014 - mae: 0.8796 - val_loss: 10.0213 - val_mae: 2.3458\n",
      "Epoch 149/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 2.5655 - mae: 1.0954 - val_loss: 10.8189 - val_mae: 2.4344\n",
      "Epoch 150/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 1.4044 - mae: 0.7892 - val_loss: 10.0281 - val_mae: 2.3738\n",
      "Epoch 151/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 2.0373 - mae: 0.9971 - val_loss: 11.0883 - val_mae: 2.4747\n",
      "Epoch 152/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 2.4116 - mae: 1.0550 - val_loss: 9.5123 - val_mae: 2.3875\n",
      "Epoch 153/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 1.6431 - mae: 0.9620 - val_loss: 13.8094 - val_mae: 2.8264\n",
      "Epoch 154/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 2.3487 - mae: 1.0980 - val_loss: 10.5923 - val_mae: 2.4279\n",
      "Epoch 155/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 2.2042 - mae: 1.0749 - val_loss: 11.0111 - val_mae: 2.5248\n",
      "Epoch 156/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 1.3073 - mae: 0.8450 - val_loss: 12.4688 - val_mae: 2.7010\n",
      "Epoch 157/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 2.3345 - mae: 1.0613 - val_loss: 10.7732 - val_mae: 2.4348\n",
      "Epoch 158/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 2.3578 - mae: 1.0464 - val_loss: 11.0597 - val_mae: 2.4617\n",
      "Epoch 159/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 1.7155 - mae: 0.9655 - val_loss: 12.9297 - val_mae: 2.6175\n",
      "Epoch 160/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 1.6968 - mae: 0.9152 - val_loss: 10.2680 - val_mae: 2.3944\n",
      "Epoch 161/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 3.1300 - mae: 1.0310 - val_loss: 12.1087 - val_mae: 2.5956\n",
      "Epoch 162/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 1.7876 - mae: 0.9319 - val_loss: 10.7643 - val_mae: 2.4508\n",
      "Epoch 163/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 2.1943 - mae: 0.9875 - val_loss: 9.7282 - val_mae: 2.3403\n",
      "Epoch 164/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 2.1392 - mae: 0.9954 - val_loss: 9.8557 - val_mae: 2.3514\n",
      "Epoch 165/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 2.9173 - mae: 1.0031 - val_loss: 12.2864 - val_mae: 2.5577\n",
      "Epoch 166/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 2.0666 - mae: 1.0420 - val_loss: 14.4759 - val_mae: 2.8510\n",
      "Epoch 167/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 2.7554 - mae: 1.0422 - val_loss: 12.1172 - val_mae: 2.6490\n",
      "Epoch 168/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 2.4268 - mae: 1.0707 - val_loss: 10.7432 - val_mae: 2.4601\n",
      "Epoch 169/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 2.9956 - mae: 1.1128 - val_loss: 10.8127 - val_mae: 2.4488\n",
      "Epoch 170/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 2.6304 - mae: 1.1394 - val_loss: 9.9122 - val_mae: 2.4221\n",
      "Epoch 171/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 1.9240 - mae: 1.0096 - val_loss: 10.5693 - val_mae: 2.3715\n",
      "Epoch 172/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 1.7869 - mae: 0.9696 - val_loss: 10.7384 - val_mae: 2.3668\n",
      "Epoch 173/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 1.5312 - mae: 0.7722 - val_loss: 12.1998 - val_mae: 2.6070\n",
      "Epoch 174/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 1.4419 - mae: 0.8509 - val_loss: 10.8988 - val_mae: 2.4580\n",
      "Epoch 175/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 1.8201 - mae: 0.9511 - val_loss: 11.3038 - val_mae: 2.4075\n",
      "Epoch 176/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 2.0745 - mae: 0.8893 - val_loss: 10.3110 - val_mae: 2.3768\n",
      "Epoch 177/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 2.6713 - mae: 1.0852 - val_loss: 9.7814 - val_mae: 2.3611\n",
      "Epoch 178/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 2.0052 - mae: 0.9441 - val_loss: 10.4553 - val_mae: 2.4310\n",
      "Epoch 179/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 1.9341 - mae: 1.0302 - val_loss: 9.9985 - val_mae: 2.3279\n",
      "Epoch 180/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 1.2214 - mae: 0.8081 - val_loss: 11.5666 - val_mae: 2.5293\n",
      "Epoch 181/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 2.0134 - mae: 1.0010 - val_loss: 9.7499 - val_mae: 2.3147\n",
      "Epoch 182/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 2.0430 - mae: 1.0206 - val_loss: 11.2867 - val_mae: 2.5252\n",
      "Epoch 183/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 2.1689 - mae: 1.0181 - val_loss: 9.8873 - val_mae: 2.2990\n",
      "Epoch 184/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 1.7597 - mae: 0.9810 - val_loss: 11.0779 - val_mae: 2.4203\n",
      "Epoch 185/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 1.7998 - mae: 0.9899 - val_loss: 11.2284 - val_mae: 2.4364\n",
      "Epoch 186/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 2.2221 - mae: 1.0099 - val_loss: 11.5461 - val_mae: 2.4970\n",
      "Epoch 187/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 1.8656 - mae: 0.9639 - val_loss: 13.1264 - val_mae: 2.6846\n",
      "Epoch 188/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.6793 - mae: 0.9358 - val_loss: 12.3092 - val_mae: 2.5658\n",
      "Epoch 189/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 1.7617 - mae: 0.9884 - val_loss: 11.7261 - val_mae: 2.4961\n",
      "Epoch 190/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 2.3683 - mae: 1.0463 - val_loss: 11.8808 - val_mae: 2.5771\n",
      "Epoch 191/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 1.5174 - mae: 0.9295 - val_loss: 12.1746 - val_mae: 2.4820\n",
      "Epoch 192/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 1.5593 - mae: 0.8930 - val_loss: 12.2884 - val_mae: 2.5799\n",
      "Epoch 193/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 1.9058 - mae: 0.9874 - val_loss: 13.3663 - val_mae: 2.7276\n",
      "Epoch 194/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 1.2918 - mae: 0.8091 - val_loss: 12.8648 - val_mae: 2.6211\n",
      "Epoch 195/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 2.1471 - mae: 0.9775 - val_loss: 12.5496 - val_mae: 2.5977\n",
      "Epoch 196/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 1.6600 - mae: 0.9494 - val_loss: 12.8850 - val_mae: 2.6852\n",
      "Epoch 197/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 1.6035 - mae: 0.9631 - val_loss: 11.1305 - val_mae: 2.3627\n",
      "Epoch 198/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 1.9856 - mae: 0.9496 - val_loss: 13.8091 - val_mae: 2.8165\n",
      "Epoch 199/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 1.5816 - mae: 0.9613 - val_loss: 11.9436 - val_mae: 2.5817\n",
      "Epoch 200/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 2.0092 - mae: 1.0327 - val_loss: 11.7047 - val_mae: 2.5473\n",
      "processing fold # 1\n",
      "Epoch 1/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 441.4844 - mae: 18.4690 - val_loss: 73.5965 - val_mae: 6.0145\n",
      "Epoch 2/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 45.5372 - mae: 4.8590 - val_loss: 40.3246 - val_mae: 4.1397\n",
      "Epoch 3/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 29.6727 - mae: 3.4728 - val_loss: 32.6969 - val_mae: 3.6515\n",
      "Epoch 4/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 20.9947 - mae: 2.7631 - val_loss: 25.7368 - val_mae: 3.1722\n",
      "Epoch 5/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 12.7352 - mae: 2.4607 - val_loss: 24.6141 - val_mae: 3.1404\n",
      "Epoch 6/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 17.5655 - mae: 2.6264 - val_loss: 22.3873 - val_mae: 3.0316\n",
      "Epoch 7/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 10.9865 - mae: 2.3883 - val_loss: 20.6687 - val_mae: 2.8736\n",
      "Epoch 8/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 10.3272 - mae: 2.1816 - val_loss: 20.8840 - val_mae: 2.9302\n",
      "Epoch 9/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 9.5413 - mae: 2.1591 - val_loss: 19.9531 - val_mae: 2.9065\n",
      "Epoch 10/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 9.2560 - mae: 2.0221 - val_loss: 17.0654 - val_mae: 2.7242\n",
      "Epoch 11/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 11.4257 - mae: 2.3100 - val_loss: 17.8956 - val_mae: 2.6901\n",
      "Epoch 12/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 6.8064 - mae: 1.8943 - val_loss: 16.3095 - val_mae: 2.7211\n",
      "Epoch 13/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 8.1137 - mae: 1.8627 - val_loss: 17.0525 - val_mae: 2.7679\n",
      "Epoch 14/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 8.5359 - mae: 1.9979 - val_loss: 22.8421 - val_mae: 3.2877\n",
      "Epoch 15/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 7.8620 - mae: 2.0403 - val_loss: 14.6733 - val_mae: 2.5909\n",
      "Epoch 16/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 10.0241 - mae: 2.1675 - val_loss: 16.0901 - val_mae: 2.6964\n",
      "Epoch 17/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 7.2735 - mae: 1.9776 - val_loss: 15.6862 - val_mae: 2.6440\n",
      "Epoch 18/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 10.2774 - mae: 1.8677 - val_loss: 14.6340 - val_mae: 2.5798\n",
      "Epoch 19/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 6.6184 - mae: 1.7781 - val_loss: 17.5556 - val_mae: 2.9046\n",
      "Epoch 20/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 5.9405 - mae: 1.7478 - val_loss: 15.1331 - val_mae: 2.6280\n",
      "Epoch 21/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 5.4066 - mae: 1.6804 - val_loss: 14.0111 - val_mae: 2.5556\n",
      "Epoch 22/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 6.2741 - mae: 1.8005 - val_loss: 15.6178 - val_mae: 2.6666\n",
      "Epoch 23/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 5.3707 - mae: 1.6261 - val_loss: 14.5871 - val_mae: 2.5838\n",
      "Epoch 24/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 6.8017 - mae: 1.6038 - val_loss: 15.2123 - val_mae: 2.6285\n",
      "Epoch 25/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 5.5928 - mae: 1.7072 - val_loss: 16.3753 - val_mae: 2.7218\n",
      "Epoch 26/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 6.0117 - mae: 1.6582 - val_loss: 15.9280 - val_mae: 2.6783\n",
      "Epoch 27/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 7.8730 - mae: 1.8314 - val_loss: 16.6235 - val_mae: 2.7754\n",
      "Epoch 28/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 4.9359 - mae: 1.6033 - val_loss: 14.1554 - val_mae: 2.5161\n",
      "Epoch 29/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 5.4809 - mae: 1.6799 - val_loss: 15.2267 - val_mae: 2.6502\n",
      "Epoch 30/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 5.7877 - mae: 1.5983 - val_loss: 14.9138 - val_mae: 2.5815\n",
      "Epoch 31/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 5.3915 - mae: 1.7197 - val_loss: 15.4968 - val_mae: 2.7002\n",
      "Epoch 32/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 4.4777 - mae: 1.5582 - val_loss: 15.8239 - val_mae: 2.6869\n",
      "Epoch 33/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 4.3129 - mae: 1.5616 - val_loss: 15.9685 - val_mae: 2.6920\n",
      "Epoch 34/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 4.8651 - mae: 1.4665 - val_loss: 15.2825 - val_mae: 2.6751\n",
      "Epoch 35/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 5.5939 - mae: 1.7346 - val_loss: 14.8582 - val_mae: 2.6569\n",
      "Epoch 36/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 5.3121 - mae: 1.5894 - val_loss: 15.9708 - val_mae: 2.7077\n",
      "Epoch 37/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 4.8262 - mae: 1.5414 - val_loss: 16.0187 - val_mae: 2.8028\n",
      "Epoch 38/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 4.5273 - mae: 1.5937 - val_loss: 15.2091 - val_mae: 2.6589\n",
      "Epoch 39/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 5.0550 - mae: 1.6500 - val_loss: 14.7285 - val_mae: 2.6130\n",
      "Epoch 40/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 3.8870 - mae: 1.4245 - val_loss: 15.1587 - val_mae: 2.6257\n",
      "Epoch 41/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 3.5041 - mae: 1.3856 - val_loss: 15.1380 - val_mae: 2.6643\n",
      "Epoch 42/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 4.4840 - mae: 1.5799 - val_loss: 16.4080 - val_mae: 2.7292\n",
      "Epoch 43/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 5.4123 - mae: 1.6186 - val_loss: 15.4592 - val_mae: 2.6816\n",
      "Epoch 44/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 3.5283 - mae: 1.3944 - val_loss: 16.2077 - val_mae: 2.8482\n",
      "Epoch 45/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 3.4478 - mae: 1.3505 - val_loss: 16.1468 - val_mae: 2.7381\n",
      "Epoch 46/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 5.0310 - mae: 1.6103 - val_loss: 15.4864 - val_mae: 2.7026\n",
      "Epoch 47/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 4.1400 - mae: 1.4338 - val_loss: 13.9739 - val_mae: 2.5497\n",
      "Epoch 48/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 3.6641 - mae: 1.3853 - val_loss: 15.1713 - val_mae: 2.6381\n",
      "Epoch 49/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 3.8206 - mae: 1.4365 - val_loss: 15.5743 - val_mae: 2.6834\n",
      "Epoch 50/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 3.5595 - mae: 1.3761 - val_loss: 14.8647 - val_mae: 2.5627\n",
      "Epoch 51/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 6.2225 - mae: 1.5742 - val_loss: 15.4387 - val_mae: 2.6476\n",
      "Epoch 52/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 3.9830 - mae: 1.3848 - val_loss: 16.1327 - val_mae: 2.8849\n",
      "Epoch 53/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 3.2256 - mae: 1.3932 - val_loss: 15.1819 - val_mae: 2.6435\n",
      "Epoch 54/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 2.8797 - mae: 1.2750 - val_loss: 14.3398 - val_mae: 2.5693\n",
      "Epoch 55/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 3.7128 - mae: 1.3779 - val_loss: 14.8942 - val_mae: 2.6607\n",
      "Epoch 56/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 3.6653 - mae: 1.4170 - val_loss: 15.1255 - val_mae: 2.6553\n",
      "Epoch 57/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 3.2729 - mae: 1.3415 - val_loss: 14.7301 - val_mae: 2.5885\n",
      "Epoch 58/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 3.1825 - mae: 1.2595 - val_loss: 17.1060 - val_mae: 2.9081\n",
      "Epoch 59/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 3.8977 - mae: 1.4845 - val_loss: 15.8500 - val_mae: 2.7341\n",
      "Epoch 60/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 2.9008 - mae: 1.1910 - val_loss: 16.5911 - val_mae: 2.8047\n",
      "Epoch 61/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 3.6841 - mae: 1.4347 - val_loss: 15.3177 - val_mae: 2.6354\n",
      "Epoch 62/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 2.9745 - mae: 1.3584 - val_loss: 16.2037 - val_mae: 2.7249\n",
      "Epoch 63/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 2.9463 - mae: 1.2943 - val_loss: 14.3359 - val_mae: 2.5385\n",
      "Epoch 64/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 3.2617 - mae: 1.2826 - val_loss: 15.1147 - val_mae: 2.6988\n",
      "Epoch 65/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 2.6015 - mae: 1.2029 - val_loss: 15.3325 - val_mae: 2.6644\n",
      "Epoch 66/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 3.2443 - mae: 1.4189 - val_loss: 15.3396 - val_mae: 2.6272\n",
      "Epoch 67/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 2.7515 - mae: 1.2672 - val_loss: 15.7246 - val_mae: 2.6535\n",
      "Epoch 68/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 2.6047 - mae: 1.1432 - val_loss: 15.6931 - val_mae: 2.7267\n",
      "Epoch 69/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 3.0693 - mae: 1.3570 - val_loss: 19.0125 - val_mae: 3.1362\n",
      "Epoch 70/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 3.7175 - mae: 1.4582 - val_loss: 15.7603 - val_mae: 2.6741\n",
      "Epoch 71/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 2.2593 - mae: 1.1062 - val_loss: 17.1822 - val_mae: 2.8786\n",
      "Epoch 72/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 2.6866 - mae: 1.2253 - val_loss: 16.1760 - val_mae: 2.7122\n",
      "Epoch 73/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 2.3929 - mae: 1.1668 - val_loss: 15.6699 - val_mae: 2.6481\n",
      "Epoch 74/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 2.4780 - mae: 1.1921 - val_loss: 16.1974 - val_mae: 2.6952\n",
      "Epoch 75/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 2.3217 - mae: 1.1888 - val_loss: 15.8240 - val_mae: 2.6547\n",
      "Epoch 76/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 2.2433 - mae: 1.1372 - val_loss: 17.4581 - val_mae: 2.8957\n",
      "Epoch 77/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 2.4046 - mae: 1.1717 - val_loss: 22.6851 - val_mae: 3.4555\n",
      "Epoch 78/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 2.5069 - mae: 1.2284 - val_loss: 17.4379 - val_mae: 2.8976\n",
      "Epoch 79/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 2.2835 - mae: 1.1429 - val_loss: 16.1266 - val_mae: 2.6897\n",
      "Epoch 80/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 2.1037 - mae: 1.1494 - val_loss: 18.5523 - val_mae: 3.0204\n",
      "Epoch 81/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 2.4960 - mae: 1.2007 - val_loss: 17.4290 - val_mae: 2.8094\n",
      "Epoch 82/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 2.5447 - mae: 1.2705 - val_loss: 16.6617 - val_mae: 2.7856\n",
      "Epoch 83/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 2.0633 - mae: 1.1204 - val_loss: 16.0050 - val_mae: 2.7700\n",
      "Epoch 84/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 2.4240 - mae: 1.1737 - val_loss: 18.5251 - val_mae: 2.9942\n",
      "Epoch 85/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 2.2048 - mae: 1.1521 - val_loss: 17.4286 - val_mae: 2.8326\n",
      "Epoch 86/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 2.1245 - mae: 1.1164 - val_loss: 16.8753 - val_mae: 2.8048\n",
      "Epoch 87/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 2.0536 - mae: 1.0877 - val_loss: 16.3459 - val_mae: 2.7001\n",
      "Epoch 88/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 1.5168 - mae: 0.9086 - val_loss: 16.5692 - val_mae: 2.6353\n",
      "Epoch 89/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 1.8894 - mae: 1.0098 - val_loss: 15.9989 - val_mae: 2.6596\n",
      "Epoch 90/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 1.5700 - mae: 0.9887 - val_loss: 18.0654 - val_mae: 2.8186\n",
      "Epoch 91/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 1.6483 - mae: 0.9908 - val_loss: 16.8995 - val_mae: 2.7079\n",
      "Epoch 92/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 1.6411 - mae: 0.9488 - val_loss: 18.1086 - val_mae: 2.7834\n",
      "Epoch 93/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 1.6506 - mae: 0.9816 - val_loss: 17.5316 - val_mae: 2.7563\n",
      "Epoch 94/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 1.7374 - mae: 1.0553 - val_loss: 18.1265 - val_mae: 2.9244\n",
      "Epoch 95/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 1.9648 - mae: 1.0666 - val_loss: 17.5893 - val_mae: 2.8463\n",
      "Epoch 96/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 1.5059 - mae: 0.9165 - val_loss: 19.1031 - val_mae: 2.9859\n",
      "Epoch 97/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 1.6170 - mae: 0.9435 - val_loss: 20.3939 - val_mae: 3.1002\n",
      "Epoch 98/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 2.0034 - mae: 0.9711 - val_loss: 18.1711 - val_mae: 2.8326\n",
      "Epoch 99/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 1.4468 - mae: 0.9094 - val_loss: 17.3833 - val_mae: 2.8169\n",
      "Epoch 100/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 1.8632 - mae: 1.0530 - val_loss: 18.7699 - val_mae: 2.9419\n",
      "Epoch 101/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 1.7806 - mae: 1.0132 - val_loss: 18.1144 - val_mae: 2.8283\n",
      "Epoch 102/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 2.0141 - mae: 0.9899 - val_loss: 16.1962 - val_mae: 2.6726\n",
      "Epoch 103/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 1.3511 - mae: 0.8662 - val_loss: 17.8852 - val_mae: 2.7742\n",
      "Epoch 104/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 2.1163 - mae: 1.0208 - val_loss: 17.5947 - val_mae: 2.7648\n",
      "Epoch 105/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.7533 - mae: 1.0027 - val_loss: 16.7706 - val_mae: 2.7010\n",
      "Epoch 106/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 1.5983 - mae: 0.9714 - val_loss: 17.4667 - val_mae: 2.7284\n",
      "Epoch 107/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 1.5014 - mae: 0.9110 - val_loss: 17.2540 - val_mae: 2.6979\n",
      "Epoch 108/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 1.3836 - mae: 0.9165 - val_loss: 16.8943 - val_mae: 2.6243\n",
      "Epoch 109/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 1.4517 - mae: 0.8979 - val_loss: 16.0058 - val_mae: 2.5737\n",
      "Epoch 110/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 1.6690 - mae: 1.0189 - val_loss: 16.7402 - val_mae: 2.6800\n",
      "Epoch 111/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 1.8137 - mae: 1.0190 - val_loss: 18.2158 - val_mae: 2.8023\n",
      "Epoch 112/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 1.4503 - mae: 0.8671 - val_loss: 17.0802 - val_mae: 2.6650\n",
      "Epoch 113/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 1.2151 - mae: 0.8339 - val_loss: 18.2443 - val_mae: 2.8372\n",
      "Epoch 114/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.7555 - mae: 0.9296 - val_loss: 18.2298 - val_mae: 2.8126\n",
      "Epoch 115/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 1.3611 - mae: 0.8915 - val_loss: 16.7825 - val_mae: 2.6049\n",
      "Epoch 116/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 1.1746 - mae: 0.7587 - val_loss: 18.1224 - val_mae: 2.8544\n",
      "Epoch 117/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 1.3715 - mae: 0.8726 - val_loss: 16.7237 - val_mae: 2.6792\n",
      "Epoch 118/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 1.2044 - mae: 0.8425 - val_loss: 18.2959 - val_mae: 2.7816\n",
      "Epoch 119/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 1.0967 - mae: 0.8361 - val_loss: 17.3031 - val_mae: 2.7405\n",
      "Epoch 120/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 1.8508 - mae: 1.0260 - val_loss: 17.6240 - val_mae: 2.7330\n",
      "Epoch 121/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 1.4555 - mae: 0.8839 - val_loss: 18.5796 - val_mae: 2.8352\n",
      "Epoch 122/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 1.5883 - mae: 0.9254 - val_loss: 16.9669 - val_mae: 2.6495\n",
      "Epoch 123/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 1.2780 - mae: 0.8502 - val_loss: 18.9776 - val_mae: 2.8547\n",
      "Epoch 124/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 1.5532 - mae: 0.9142 - val_loss: 19.2195 - val_mae: 2.9260\n",
      "Epoch 125/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 1.2379 - mae: 0.8066 - val_loss: 18.4912 - val_mae: 2.7705\n",
      "Epoch 126/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 1.3330 - mae: 0.9143 - val_loss: 17.2087 - val_mae: 2.7025\n",
      "Epoch 127/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 1.0772 - mae: 0.7838 - val_loss: 17.8308 - val_mae: 2.7368\n",
      "Epoch 128/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 1.1169 - mae: 0.8192 - val_loss: 17.3723 - val_mae: 2.7233\n",
      "Epoch 129/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 1.2809 - mae: 0.8697 - val_loss: 19.3495 - val_mae: 3.0629\n",
      "Epoch 130/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 1.0719 - mae: 0.7758 - val_loss: 17.1781 - val_mae: 2.7027\n",
      "Epoch 131/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 1.7867 - mae: 0.9516 - val_loss: 17.8597 - val_mae: 2.7569\n",
      "Epoch 132/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 1.1324 - mae: 0.7845 - val_loss: 18.7093 - val_mae: 2.8864\n",
      "Epoch 133/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.9892 - mae: 0.7410 - val_loss: 16.7478 - val_mae: 2.6738\n",
      "Epoch 134/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 1.3667 - mae: 0.8356 - val_loss: 17.8726 - val_mae: 2.7594\n",
      "Epoch 135/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 1.2461 - mae: 0.8066 - val_loss: 17.4105 - val_mae: 2.7195\n",
      "Epoch 136/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 1.8245 - mae: 0.8876 - val_loss: 18.5681 - val_mae: 2.8848\n",
      "Epoch 137/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.9567 - mae: 0.7539 - val_loss: 17.4323 - val_mae: 2.7699\n",
      "Epoch 138/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 1.2165 - mae: 0.8410 - val_loss: 18.2248 - val_mae: 2.7757\n",
      "Epoch 139/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 1.2955 - mae: 0.8573 - val_loss: 19.3839 - val_mae: 3.0091\n",
      "Epoch 140/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 1.0779 - mae: 0.7783 - val_loss: 17.9935 - val_mae: 2.7907\n",
      "Epoch 141/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 1.4037 - mae: 0.8445 - val_loss: 18.0439 - val_mae: 2.8095\n",
      "Epoch 142/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.8556 - mae: 0.7163 - val_loss: 18.2560 - val_mae: 2.8257\n",
      "Epoch 143/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 1.0198 - mae: 0.7341 - val_loss: 18.3828 - val_mae: 2.8361\n",
      "Epoch 144/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.7974 - mae: 0.7019 - val_loss: 19.0736 - val_mae: 3.0241\n",
      "Epoch 145/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 1.0344 - mae: 0.7691 - val_loss: 17.0447 - val_mae: 2.6916\n",
      "Epoch 146/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 1.2832 - mae: 0.7503 - val_loss: 18.4295 - val_mae: 2.8464\n",
      "Epoch 147/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 1.1371 - mae: 0.8013 - val_loss: 18.0377 - val_mae: 2.8016\n",
      "Epoch 148/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.9439 - mae: 0.7124 - val_loss: 17.4310 - val_mae: 2.7140\n",
      "Epoch 149/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.8996 - mae: 0.7332 - val_loss: 19.5452 - val_mae: 2.9157\n",
      "Epoch 150/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 1.0348 - mae: 0.7861 - val_loss: 17.5498 - val_mae: 2.8593\n",
      "Epoch 151/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 1.0841 - mae: 0.7965 - val_loss: 21.2209 - val_mae: 3.1766\n",
      "Epoch 152/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.8497 - mae: 0.7187 - val_loss: 18.2172 - val_mae: 2.7982\n",
      "Epoch 153/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.9096 - mae: 0.6934 - val_loss: 18.3255 - val_mae: 2.8449\n",
      "Epoch 154/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.8737 - mae: 0.6872 - val_loss: 19.7838 - val_mae: 2.9057\n",
      "Epoch 155/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 1.1563 - mae: 0.8221 - val_loss: 18.6421 - val_mae: 2.8310\n",
      "Epoch 156/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.9635 - mae: 0.7356 - val_loss: 18.2378 - val_mae: 2.7567\n",
      "Epoch 157/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.9629 - mae: 0.7332 - val_loss: 18.7153 - val_mae: 2.8214\n",
      "Epoch 158/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 1.1982 - mae: 0.8455 - val_loss: 17.9305 - val_mae: 2.7798\n",
      "Epoch 159/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.8133 - mae: 0.6705 - val_loss: 18.7454 - val_mae: 2.8542\n",
      "Epoch 160/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.9601 - mae: 0.7339 - val_loss: 18.4642 - val_mae: 2.9014\n",
      "Epoch 161/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 1.0604 - mae: 0.7873 - val_loss: 18.0505 - val_mae: 2.8443\n",
      "Epoch 162/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 1.4227 - mae: 0.8292 - val_loss: 17.5369 - val_mae: 2.7712\n",
      "Epoch 163/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.7754 - mae: 0.6528 - val_loss: 18.4028 - val_mae: 2.8418\n",
      "Epoch 164/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.8799 - mae: 0.7450 - val_loss: 18.4002 - val_mae: 2.9165\n",
      "Epoch 165/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.9444 - mae: 0.7415 - val_loss: 20.6259 - val_mae: 3.1632\n",
      "Epoch 166/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 1.1054 - mae: 0.8012 - val_loss: 18.7707 - val_mae: 2.9310\n",
      "Epoch 167/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.8777 - mae: 0.6790 - val_loss: 18.0417 - val_mae: 2.8385\n",
      "Epoch 168/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.9812 - mae: 0.7273 - val_loss: 19.1040 - val_mae: 2.9713\n",
      "Epoch 169/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.8674 - mae: 0.6674 - val_loss: 18.3334 - val_mae: 2.9028\n",
      "Epoch 170/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 1.2552 - mae: 0.8112 - val_loss: 19.9969 - val_mae: 3.0903\n",
      "Epoch 171/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 1.1835 - mae: 0.7663 - val_loss: 18.6525 - val_mae: 2.8720\n",
      "Epoch 172/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.0461 - mae: 0.7299 - val_loss: 18.4555 - val_mae: 2.8818\n",
      "Epoch 173/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.9184 - mae: 0.6881 - val_loss: 18.2493 - val_mae: 2.8224\n",
      "Epoch 174/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.9248 - mae: 0.7066 - val_loss: 18.2632 - val_mae: 2.8757\n",
      "Epoch 175/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.7636 - mae: 0.6007 - val_loss: 17.8342 - val_mae: 2.8265\n",
      "Epoch 176/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 1.1251 - mae: 0.8105 - val_loss: 18.7226 - val_mae: 2.9207\n",
      "Epoch 177/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.8593 - mae: 0.7023 - val_loss: 17.7835 - val_mae: 2.7993\n",
      "Epoch 178/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.8426 - mae: 0.6907 - val_loss: 17.5165 - val_mae: 2.6896\n",
      "Epoch 179/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.9080 - mae: 0.7410 - val_loss: 18.5543 - val_mae: 2.8354\n",
      "Epoch 180/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.9347 - mae: 0.7001 - val_loss: 17.6198 - val_mae: 2.7833\n",
      "Epoch 181/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.9922 - mae: 0.7426 - val_loss: 17.5776 - val_mae: 2.7144\n",
      "Epoch 182/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.9068 - mae: 0.6785 - val_loss: 18.5954 - val_mae: 2.8453\n",
      "Epoch 183/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.8330 - mae: 0.6479 - val_loss: 19.6477 - val_mae: 2.9529\n",
      "Epoch 184/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.9851 - mae: 0.7198 - val_loss: 18.4586 - val_mae: 2.8586\n",
      "Epoch 185/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.9416 - mae: 0.7047 - val_loss: 18.9900 - val_mae: 2.9116\n",
      "Epoch 186/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.9211 - mae: 0.6966 - val_loss: 17.9805 - val_mae: 2.8594\n",
      "Epoch 187/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 1.0190 - mae: 0.7365 - val_loss: 19.3929 - val_mae: 2.8955\n",
      "Epoch 188/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.9286 - mae: 0.7222 - val_loss: 18.0591 - val_mae: 2.8453\n",
      "Epoch 189/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.5647 - mae: 0.5692 - val_loss: 19.1402 - val_mae: 2.9145\n",
      "Epoch 190/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 1.1915 - mae: 0.7639 - val_loss: 17.9413 - val_mae: 2.8302\n",
      "Epoch 191/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.8598 - mae: 0.7149 - val_loss: 18.2114 - val_mae: 2.8502\n",
      "Epoch 192/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.6585 - mae: 0.6239 - val_loss: 19.5796 - val_mae: 2.9191\n",
      "Epoch 193/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.8930 - mae: 0.6947 - val_loss: 18.2588 - val_mae: 2.8305\n",
      "Epoch 194/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1.0286 - mae: 0.7293 - val_loss: 19.0062 - val_mae: 2.9507\n",
      "Epoch 195/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.7041 - mae: 0.6031 - val_loss: 18.5965 - val_mae: 2.9083\n",
      "Epoch 196/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.7613 - mae: 0.6743 - val_loss: 19.3116 - val_mae: 2.9324\n",
      "Epoch 197/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.7586 - mae: 0.6868 - val_loss: 18.3413 - val_mae: 2.8164\n",
      "Epoch 198/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.9720 - mae: 0.7098 - val_loss: 17.5171 - val_mae: 2.7842\n",
      "Epoch 199/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.9217 - mae: 0.7062 - val_loss: 17.8892 - val_mae: 2.8213\n",
      "Epoch 200/200\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.8557 - mae: 0.6809 - val_loss: 18.2362 - val_mae: 2.8508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/303 [============================>.] - ETA: 0s - loss: 190.0997 - mae: 10.1670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 18:54:01.957790: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 2s 6ms/step - loss: 188.1547 - mae: 10.1118 - val_loss: 77.3815 - val_mae: 6.1077\n",
      "Epoch 2/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 31.5356 - mae: 3.7849 - val_loss: 42.5981 - val_mae: 4.1800\n",
      "Epoch 3/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 21.4721 - mae: 3.0919 - val_loss: 31.6504 - val_mae: 3.6330\n",
      "Epoch 4/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 17.2931 - mae: 2.6530 - val_loss: 32.7745 - val_mae: 3.4435\n",
      "Epoch 5/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 15.2716 - mae: 2.5075 - val_loss: 29.5661 - val_mae: 3.2947\n",
      "Epoch 6/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 14.5992 - mae: 2.4564 - val_loss: 23.6707 - val_mae: 3.0034\n",
      "Epoch 7/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 13.4987 - mae: 2.3026 - val_loss: 24.0354 - val_mae: 2.9566\n",
      "Epoch 8/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 12.7599 - mae: 2.2790 - val_loss: 24.1899 - val_mae: 2.8975\n",
      "Epoch 9/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 12.4545 - mae: 2.2129 - val_loss: 21.4596 - val_mae: 2.8218\n",
      "Epoch 10/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 11.8787 - mae: 2.2266 - val_loss: 20.6914 - val_mae: 2.6765\n",
      "Epoch 11/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 11.7591 - mae: 2.2173 - val_loss: 21.4839 - val_mae: 2.7194\n",
      "Epoch 12/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 11.0406 - mae: 2.0716 - val_loss: 20.9385 - val_mae: 2.9205\n",
      "Epoch 13/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 11.1902 - mae: 2.1392 - val_loss: 17.9045 - val_mae: 2.5992\n",
      "Epoch 14/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 10.2286 - mae: 2.0930 - val_loss: 21.3403 - val_mae: 2.7082\n",
      "Epoch 15/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 10.7698 - mae: 2.0475 - val_loss: 19.3772 - val_mae: 2.6990\n",
      "Epoch 16/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 10.4368 - mae: 2.0484 - val_loss: 16.3167 - val_mae: 2.5450\n",
      "Epoch 17/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 9.9526 - mae: 2.0238 - val_loss: 18.9242 - val_mae: 2.6610\n",
      "Epoch 18/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 9.2417 - mae: 1.9635 - val_loss: 18.1351 - val_mae: 2.7531\n",
      "Epoch 19/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 9.5081 - mae: 1.9466 - val_loss: 17.0690 - val_mae: 2.6833\n",
      "Epoch 20/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 9.3234 - mae: 1.9485 - val_loss: 20.8560 - val_mae: 2.8375\n",
      "Epoch 21/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 9.5064 - mae: 1.9248 - val_loss: 17.8716 - val_mae: 2.6805\n",
      "Epoch 22/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.9685 - mae: 1.9179 - val_loss: 15.5901 - val_mae: 2.5562\n",
      "Epoch 23/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 9.0061 - mae: 1.9544 - val_loss: 16.4902 - val_mae: 2.6089\n",
      "Epoch 24/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 8.4740 - mae: 1.8177 - val_loss: 16.2042 - val_mae: 2.6776\n",
      "Epoch 25/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 8.6378 - mae: 1.8722 - val_loss: 15.6932 - val_mae: 2.5383\n",
      "Epoch 26/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 8.7876 - mae: 1.9194 - val_loss: 15.4495 - val_mae: 2.5458\n",
      "Epoch 27/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.2560 - mae: 1.8452 - val_loss: 17.8059 - val_mae: 2.8922\n",
      "Epoch 28/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 8.2897 - mae: 1.8801 - val_loss: 15.9076 - val_mae: 2.6169\n",
      "Epoch 29/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.9476 - mae: 1.8174 - val_loss: 15.2237 - val_mae: 2.6769\n",
      "Epoch 30/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.9735 - mae: 1.8525 - val_loss: 17.3894 - val_mae: 2.7598\n",
      "Epoch 31/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 8.1110 - mae: 1.8000 - val_loss: 16.8863 - val_mae: 2.7146\n",
      "Epoch 32/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.8967 - mae: 1.7868 - val_loss: 14.9275 - val_mae: 2.6280\n",
      "Epoch 33/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.8845 - mae: 1.7747 - val_loss: 16.5004 - val_mae: 2.7344\n",
      "Epoch 34/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.6006 - mae: 1.7136 - val_loss: 19.2082 - val_mae: 3.0276\n",
      "Epoch 35/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 8.4997 - mae: 1.7497 - val_loss: 16.9008 - val_mae: 2.7277\n",
      "Epoch 36/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.7851 - mae: 1.8308 - val_loss: 15.6070 - val_mae: 2.6861\n",
      "Epoch 37/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.7559 - mae: 1.7045 - val_loss: 15.2427 - val_mae: 2.7581\n",
      "Epoch 38/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.4642 - mae: 1.7604 - val_loss: 14.8208 - val_mae: 2.5734\n",
      "Epoch 39/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.8157 - mae: 1.8052 - val_loss: 13.8014 - val_mae: 2.4705\n",
      "Epoch 40/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.2044 - mae: 1.7437 - val_loss: 14.3941 - val_mae: 2.5918\n",
      "Epoch 41/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 7.2844 - mae: 1.7009 - val_loss: 14.0421 - val_mae: 2.5360\n",
      "Epoch 42/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.7174 - mae: 1.6930 - val_loss: 16.2253 - val_mae: 2.8244\n",
      "Epoch 43/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 6.7615 - mae: 1.6725 - val_loss: 15.3821 - val_mae: 2.6830\n",
      "Epoch 44/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.3298 - mae: 1.7302 - val_loss: 14.0414 - val_mae: 2.5734\n",
      "Epoch 45/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 7.0017 - mae: 1.6526 - val_loss: 14.4014 - val_mae: 2.6034\n",
      "Epoch 46/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.2931 - mae: 1.6257 - val_loss: 14.7462 - val_mae: 2.6829\n",
      "Epoch 47/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.9327 - mae: 1.6329 - val_loss: 14.1018 - val_mae: 2.5958\n",
      "Epoch 48/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.1990 - mae: 1.6594 - val_loss: 13.2481 - val_mae: 2.5035\n",
      "Epoch 49/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.1499 - mae: 1.6499 - val_loss: 13.7072 - val_mae: 2.5504\n",
      "Epoch 50/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.5567 - mae: 1.6258 - val_loss: 13.6018 - val_mae: 2.5653\n",
      "Epoch 51/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.1723 - mae: 1.5884 - val_loss: 14.4214 - val_mae: 2.6280\n",
      "Epoch 52/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.4575 - mae: 1.6029 - val_loss: 13.4553 - val_mae: 2.4829\n",
      "Epoch 53/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.5768 - mae: 1.6070 - val_loss: 13.4010 - val_mae: 2.5272\n",
      "Epoch 54/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.3887 - mae: 1.5847 - val_loss: 14.3874 - val_mae: 2.6532\n",
      "Epoch 55/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.2179 - mae: 1.6003 - val_loss: 15.2930 - val_mae: 2.8040\n",
      "Epoch 56/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.7862 - mae: 1.5795 - val_loss: 13.4226 - val_mae: 2.5758\n",
      "Epoch 57/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.1000 - mae: 1.5615 - val_loss: 14.1999 - val_mae: 2.6926\n",
      "Epoch 58/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 6.3749 - mae: 1.5484 - val_loss: 13.3899 - val_mae: 2.4898\n",
      "Epoch 59/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.8701 - mae: 1.5378 - val_loss: 13.6655 - val_mae: 2.5466\n",
      "Epoch 60/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.6484 - mae: 1.5358 - val_loss: 14.1841 - val_mae: 2.6760\n",
      "Epoch 61/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.5788 - mae: 1.4948 - val_loss: 13.1159 - val_mae: 2.5078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.6793 - mae: 1.5524 - val_loss: 13.0727 - val_mae: 2.4786\n",
      "Epoch 63/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.7634 - mae: 1.5356 - val_loss: 12.8484 - val_mae: 2.4677\n",
      "Epoch 64/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.7534 - mae: 1.5764 - val_loss: 12.3504 - val_mae: 2.4318\n",
      "Epoch 65/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.5824 - mae: 1.4903 - val_loss: 13.4326 - val_mae: 2.5669\n",
      "Epoch 66/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.3899 - mae: 1.4408 - val_loss: 16.1374 - val_mae: 2.9007\n",
      "Epoch 67/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.5314 - mae: 1.4587 - val_loss: 14.2370 - val_mae: 2.6056\n",
      "Epoch 68/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.5881 - mae: 1.5024 - val_loss: 14.1704 - val_mae: 2.5550\n",
      "Epoch 69/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.2237 - mae: 1.4913 - val_loss: 13.0192 - val_mae: 2.4985\n",
      "Epoch 70/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 5.7500 - mae: 1.4935 - val_loss: 13.3093 - val_mae: 2.5779\n",
      "Epoch 71/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.2291 - mae: 1.4852 - val_loss: 13.6400 - val_mae: 2.6159\n",
      "Epoch 72/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.3111 - mae: 1.4638 - val_loss: 13.9916 - val_mae: 2.5660\n",
      "Epoch 73/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.3303 - mae: 1.4226 - val_loss: 13.6904 - val_mae: 2.5694\n",
      "Epoch 74/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.3273 - mae: 1.4145 - val_loss: 13.7204 - val_mae: 2.6035\n",
      "Epoch 75/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.4431 - mae: 1.4621 - val_loss: 13.3262 - val_mae: 2.4636\n",
      "Epoch 76/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.7835 - mae: 1.3887 - val_loss: 13.6489 - val_mae: 2.5878\n",
      "Epoch 77/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.1804 - mae: 1.4134 - val_loss: 13.8621 - val_mae: 2.6667\n",
      "Epoch 78/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.1198 - mae: 1.4167 - val_loss: 13.2810 - val_mae: 2.4806\n",
      "Epoch 79/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.9147 - mae: 1.4475 - val_loss: 11.9606 - val_mae: 2.3612\n",
      "Epoch 80/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 5.1158 - mae: 1.4121 - val_loss: 14.7042 - val_mae: 2.7469\n",
      "Epoch 81/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.9644 - mae: 1.4120 - val_loss: 13.1094 - val_mae: 2.4467\n",
      "Epoch 82/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.6913 - mae: 1.3918 - val_loss: 14.4253 - val_mae: 2.5591\n",
      "Epoch 83/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.8599 - mae: 1.3768 - val_loss: 13.6899 - val_mae: 2.5503\n",
      "Epoch 84/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.8780 - mae: 1.4033 - val_loss: 14.0779 - val_mae: 2.6822\n",
      "Epoch 85/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.6628 - mae: 1.3585 - val_loss: 13.1060 - val_mae: 2.4912\n",
      "Epoch 86/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.8081 - mae: 1.3947 - val_loss: 12.7931 - val_mae: 2.5249\n",
      "Epoch 87/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.8179 - mae: 1.3688 - val_loss: 13.3503 - val_mae: 2.6139\n",
      "Epoch 88/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.3314 - mae: 1.3474 - val_loss: 14.0425 - val_mae: 2.5686\n",
      "Epoch 89/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.5499 - mae: 1.3282 - val_loss: 14.5768 - val_mae: 2.5848\n",
      "Epoch 90/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.6719 - mae: 1.3885 - val_loss: 12.5869 - val_mae: 2.3899\n",
      "Epoch 91/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.5502 - mae: 1.3679 - val_loss: 13.9773 - val_mae: 2.5812\n",
      "Epoch 92/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.6649 - mae: 1.3454 - val_loss: 13.0686 - val_mae: 2.5275\n",
      "Epoch 93/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.6562 - mae: 1.3048 - val_loss: 13.1249 - val_mae: 2.5651\n",
      "Epoch 94/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.3757 - mae: 1.2978 - val_loss: 12.6952 - val_mae: 2.4530\n",
      "Epoch 95/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.7605 - mae: 1.3118 - val_loss: 12.6812 - val_mae: 2.4231\n",
      "Epoch 96/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.4762 - mae: 1.3337 - val_loss: 13.1380 - val_mae: 2.4148\n",
      "Epoch 97/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.5541 - mae: 1.3095 - val_loss: 12.4994 - val_mae: 2.3687\n",
      "Epoch 98/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.4164 - mae: 1.3117 - val_loss: 13.0281 - val_mae: 2.4425\n",
      "Epoch 99/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.4509 - mae: 1.2757 - val_loss: 13.4832 - val_mae: 2.4786\n",
      "Epoch 100/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.0688 - mae: 1.2778 - val_loss: 14.1487 - val_mae: 2.6176\n",
      "Epoch 101/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.6564 - mae: 1.3026 - val_loss: 14.0658 - val_mae: 2.5593\n",
      "Epoch 102/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.1623 - mae: 1.3026 - val_loss: 15.0640 - val_mae: 2.6510\n",
      "Epoch 103/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.3063 - mae: 1.3043 - val_loss: 13.4881 - val_mae: 2.4667\n",
      "Epoch 104/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.2877 - mae: 1.3004 - val_loss: 12.8999 - val_mae: 2.4730\n",
      "Epoch 105/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.1341 - mae: 1.2689 - val_loss: 12.5112 - val_mae: 2.4313\n",
      "Epoch 106/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.9677 - mae: 1.2392 - val_loss: 13.2568 - val_mae: 2.5792\n",
      "Epoch 107/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.1418 - mae: 1.2507 - val_loss: 13.2553 - val_mae: 2.4741\n",
      "Epoch 108/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.1271 - mae: 1.3211 - val_loss: 13.9111 - val_mae: 2.5539\n",
      "Epoch 109/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.7540 - mae: 1.2243 - val_loss: 13.3654 - val_mae: 2.5089\n",
      "Epoch 110/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.0593 - mae: 1.2399 - val_loss: 13.6365 - val_mae: 2.5987\n",
      "Epoch 111/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.0712 - mae: 1.2552 - val_loss: 16.2066 - val_mae: 2.8775\n",
      "Epoch 112/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.0737 - mae: 1.2946 - val_loss: 13.6179 - val_mae: 2.4934\n",
      "Epoch 113/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.9585 - mae: 1.2155 - val_loss: 13.5117 - val_mae: 2.5071\n",
      "Epoch 114/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.0933 - mae: 1.2600 - val_loss: 13.8194 - val_mae: 2.4332\n",
      "Epoch 115/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.6662 - mae: 1.2460 - val_loss: 12.9402 - val_mae: 2.5184\n",
      "Epoch 116/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.0316 - mae: 1.2507 - val_loss: 14.1320 - val_mae: 2.5444\n",
      "Epoch 117/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.9249 - mae: 1.2967 - val_loss: 14.0313 - val_mae: 2.5412\n",
      "Epoch 118/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 4.0228 - mae: 1.2113 - val_loss: 14.8443 - val_mae: 2.7823\n",
      "Epoch 119/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.5606 - mae: 1.2235 - val_loss: 13.9813 - val_mae: 2.4461\n",
      "Epoch 120/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.8132 - mae: 1.2432 - val_loss: 14.6810 - val_mae: 2.5128\n",
      "Epoch 121/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 4.0494 - mae: 1.2154 - val_loss: 14.0512 - val_mae: 2.5548\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 2s 5ms/step - loss: 3.8727 - mae: 1.1715 - val_loss: 14.8186 - val_mae: 2.5766\n",
      "Epoch 123/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.8589 - mae: 1.2020 - val_loss: 13.9807 - val_mae: 2.5377\n",
      "Epoch 124/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.7567 - mae: 1.2157 - val_loss: 13.4192 - val_mae: 2.4912\n",
      "Epoch 125/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.6954 - mae: 1.1630 - val_loss: 16.7090 - val_mae: 2.9738\n",
      "Epoch 126/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.8093 - mae: 1.1801 - val_loss: 13.9868 - val_mae: 2.5138\n",
      "Epoch 127/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.9534 - mae: 1.2263 - val_loss: 13.2821 - val_mae: 2.4641\n",
      "Epoch 128/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.7799 - mae: 1.1657 - val_loss: 13.5005 - val_mae: 2.4458\n",
      "Epoch 129/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.6964 - mae: 1.2312 - val_loss: 14.2726 - val_mae: 2.6230\n",
      "Epoch 130/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.4788 - mae: 1.2091 - val_loss: 14.4564 - val_mae: 2.5925\n",
      "Epoch 131/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.8201 - mae: 1.1915 - val_loss: 14.3998 - val_mae: 2.6629\n",
      "Epoch 132/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.6930 - mae: 1.1788 - val_loss: 14.1897 - val_mae: 2.5072\n",
      "Epoch 133/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.4880 - mae: 1.2054 - val_loss: 13.5096 - val_mae: 2.4879\n",
      "Epoch 134/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.5461 - mae: 1.1985 - val_loss: 13.1294 - val_mae: 2.5026\n",
      "Epoch 135/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.3576 - mae: 1.1545 - val_loss: 13.6417 - val_mae: 2.4965\n",
      "Epoch 136/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.4580 - mae: 1.1837 - val_loss: 13.7448 - val_mae: 2.4883\n",
      "Epoch 137/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.6593 - mae: 1.1655 - val_loss: 14.1748 - val_mae: 2.6455\n",
      "Epoch 138/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.4066 - mae: 1.1703 - val_loss: 13.0577 - val_mae: 2.3890\n",
      "Epoch 139/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.4256 - mae: 1.1074 - val_loss: 13.2020 - val_mae: 2.4397\n",
      "Epoch 140/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.3196 - mae: 1.1508 - val_loss: 13.6045 - val_mae: 2.4431\n",
      "Epoch 141/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.0979 - mae: 1.1178 - val_loss: 14.2114 - val_mae: 2.6170\n",
      "Epoch 142/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.6676 - mae: 1.1900 - val_loss: 13.7551 - val_mae: 2.5252\n",
      "Epoch 143/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.2122 - mae: 1.0986 - val_loss: 13.3097 - val_mae: 2.5424\n",
      "Epoch 144/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.4273 - mae: 1.1519 - val_loss: 13.6249 - val_mae: 2.5969\n",
      "Epoch 145/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.5125 - mae: 1.1528 - val_loss: 13.5001 - val_mae: 2.5334\n",
      "Epoch 146/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.2386 - mae: 1.1334 - val_loss: 17.9074 - val_mae: 2.9895\n",
      "Epoch 147/200\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 3.2615 - mae: 1.1522 - val_loss: 14.0222 - val_mae: 2.5695\n",
      "Epoch 148/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.0962 - mae: 1.1367 - val_loss: 14.9697 - val_mae: 2.6639\n",
      "Epoch 149/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.3574 - mae: 1.1058 - val_loss: 14.7662 - val_mae: 2.5804\n",
      "Epoch 150/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.1592 - mae: 1.1244 - val_loss: 13.6274 - val_mae: 2.4899\n",
      "Epoch 151/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.1585 - mae: 1.1655 - val_loss: 15.2175 - val_mae: 2.8578\n",
      "Epoch 152/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.3108 - mae: 1.1432 - val_loss: 13.6100 - val_mae: 2.5172\n",
      "Epoch 153/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.2927 - mae: 1.1440 - val_loss: 13.6674 - val_mae: 2.6210\n",
      "Epoch 154/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.8991 - mae: 1.0661 - val_loss: 15.4541 - val_mae: 2.7911\n",
      "Epoch 155/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.1741 - mae: 1.1096 - val_loss: 14.0737 - val_mae: 2.6139\n",
      "Epoch 156/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.1272 - mae: 1.1124 - val_loss: 14.1453 - val_mae: 2.5509\n",
      "Epoch 157/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.1691 - mae: 1.1475 - val_loss: 14.5327 - val_mae: 2.6537\n",
      "Epoch 158/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.0746 - mae: 1.1413 - val_loss: 14.1012 - val_mae: 2.6017\n",
      "Epoch 159/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.9148 - mae: 1.1014 - val_loss: 13.0282 - val_mae: 2.5101\n",
      "Epoch 160/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.0748 - mae: 1.0984 - val_loss: 13.8022 - val_mae: 2.5397\n",
      "Epoch 161/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.0157 - mae: 1.0891 - val_loss: 14.3138 - val_mae: 2.6017\n",
      "Epoch 162/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.0698 - mae: 1.0733 - val_loss: 14.7438 - val_mae: 2.7232\n",
      "Epoch 163/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.9085 - mae: 1.0469 - val_loss: 15.0766 - val_mae: 2.8457\n",
      "Epoch 164/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.9991 - mae: 1.1211 - val_loss: 14.5345 - val_mae: 2.6285\n",
      "Epoch 165/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.9614 - mae: 1.0836 - val_loss: 15.1346 - val_mae: 2.8180\n",
      "Epoch 166/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 2.9686 - mae: 1.1225 - val_loss: 14.7535 - val_mae: 2.7728\n",
      "Epoch 167/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.2048 - mae: 1.1092 - val_loss: 15.2710 - val_mae: 2.6483\n",
      "Epoch 168/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.8252 - mae: 1.0892 - val_loss: 14.5878 - val_mae: 2.6635\n",
      "Epoch 169/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.2252 - mae: 1.0862 - val_loss: 13.3348 - val_mae: 2.4617\n",
      "Epoch 170/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 2.8998 - mae: 1.0890 - val_loss: 13.8075 - val_mae: 2.6073\n",
      "Epoch 171/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 2.8512 - mae: 1.0741 - val_loss: 13.9160 - val_mae: 2.6261\n",
      "Epoch 172/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.9936 - mae: 1.1518 - val_loss: 15.1836 - val_mae: 2.7342\n",
      "Epoch 173/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.6589 - mae: 1.0330 - val_loss: 14.0157 - val_mae: 2.6124\n",
      "Epoch 174/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.9102 - mae: 1.1124 - val_loss: 15.9322 - val_mae: 2.8287\n",
      "Epoch 175/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 3.0440 - mae: 1.0832 - val_loss: 15.5491 - val_mae: 2.7633\n",
      "Epoch 176/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 2.7915 - mae: 1.1060 - val_loss: 14.8784 - val_mae: 2.6481\n",
      "Epoch 177/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.7844 - mae: 1.0431 - val_loss: 13.4844 - val_mae: 2.5871\n",
      "Epoch 178/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.7729 - mae: 1.0399 - val_loss: 13.3452 - val_mae: 2.5433\n",
      "Epoch 179/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.9707 - mae: 1.1086 - val_loss: 14.2412 - val_mae: 2.5812\n",
      "Epoch 180/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.6581 - mae: 1.0259 - val_loss: 14.6204 - val_mae: 2.6710\n",
      "Epoch 181/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.6455 - mae: 1.0885 - val_loss: 16.3919 - val_mae: 2.9419\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 2s 6ms/step - loss: 2.9153 - mae: 1.0710 - val_loss: 14.4020 - val_mae: 2.6757\n",
      "Epoch 183/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.5706 - mae: 1.0449 - val_loss: 16.4305 - val_mae: 2.8434\n",
      "Epoch 184/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.4568 - mae: 1.0104 - val_loss: 15.1413 - val_mae: 2.8519\n",
      "Epoch 185/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.7782 - mae: 1.0634 - val_loss: 14.0173 - val_mae: 2.6170\n",
      "Epoch 186/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.8400 - mae: 1.0851 - val_loss: 15.5859 - val_mae: 2.7436\n",
      "Epoch 187/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 2.6408 - mae: 1.0960 - val_loss: 13.6565 - val_mae: 2.5736\n",
      "Epoch 188/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.7103 - mae: 1.0609 - val_loss: 14.0486 - val_mae: 2.7317\n",
      "Epoch 189/200\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 2.7375 - mae: 1.0362 - val_loss: 15.3355 - val_mae: 2.6753\n",
      "Epoch 190/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.6448 - mae: 1.0531 - val_loss: 16.3780 - val_mae: 2.8578\n",
      "Epoch 191/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.4769 - mae: 0.9876 - val_loss: 15.5403 - val_mae: 2.7184\n",
      "Epoch 192/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.6289 - mae: 1.0757 - val_loss: 14.7150 - val_mae: 2.6855\n",
      "Epoch 193/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.5773 - mae: 1.0630 - val_loss: 14.2091 - val_mae: 2.6637\n",
      "Epoch 194/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.3671 - mae: 1.0007 - val_loss: 15.6104 - val_mae: 2.7629\n",
      "Epoch 195/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.5779 - mae: 1.0602 - val_loss: 14.0811 - val_mae: 2.5771\n",
      "Epoch 196/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.5285 - mae: 0.9784 - val_loss: 15.0717 - val_mae: 2.7803\n",
      "Epoch 197/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.5036 - mae: 1.0110 - val_loss: 15.6801 - val_mae: 2.8524\n",
      "Epoch 198/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.4051 - mae: 1.0481 - val_loss: 15.0206 - val_mae: 2.8496\n",
      "Epoch 199/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.5043 - mae: 1.0999 - val_loss: 14.3498 - val_mae: 2.6518\n",
      "Epoch 200/200\n",
      "303/303 [==============================] - 2s 5ms/step - loss: 2.4094 - mae: 1.0101 - val_loss: 13.6285 - val_mae: 2.5472\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the average of the per-epoch MAE scores for all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It may be a bit hard to see the plot due to scaling issues and relatively high variance. Let's:\n",
    "\n",
    "* Omit the first 10 data points, which are on a different scale from the rest of the curve.\n",
    "* Replace each point with an exponential moving average of the previous points, to obtain a smooth curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "According to this plot, it seems that validation MAE stops improving significantly after 70 epochs. Past that point, we start overfitting.\n",
    "\n",
    "Once we are done tuning other parameters of our model (besides the number of epochs, we could also adjust the size of the hidden layers), we \n",
    "can train a final \"production\" model on all of the training data, with the best parameters, then look at its performance on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.9083 - mae: 2.6641\n"
     ]
    }
   ],
   "source": [
    "# Get a fresh, compiled model.\n",
    "model = build_model()\n",
    "# Train it on the entirety of the data.\n",
    "model.fit(train_data, train_targets,\n",
    "          epochs=70, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.866039991378784"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still off by about \\$2,866."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "\n",
    "Here's what you should take away from this example:\n",
    "\n",
    "* Regression is done using different loss functions from classification; Mean Squared Error (MSE) is a commonly used loss function for \n",
    "regression.\n",
    "* Similarly, evaluation metrics to be used for regression differ from those used for classification; naturally the concept of \"accuracy\" \n",
    "does not apply for regression. A common regression metric is Mean Absolute Error (MAE).\n",
    "* When features in the input data have values in different ranges, each feature should be scaled independently as a preprocessing step.\n",
    "* When there is little data available, using K-Fold validation is a great way to reliably evaluate a model.\n",
    "* When little training data is available, it is preferable to use a small network with very few hidden layers (typically only one or two), \n",
    "in order to avoid severe overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCIE89",
   "language": "python",
   "name": "cscie89"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
